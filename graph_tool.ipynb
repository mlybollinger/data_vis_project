{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR6Ow9uxoFB-",
        "outputId": "802e1a14-ad6b-4c20-f4c1-cd4beae62ee8"
      },
      "outputs": [
      ],
      "source": [
        "#Commands for installing graph-tool package on Google Colab\n",
        "!echo \"deb http://downloads.skewed.de/apt bionic main\" >> /etc/apt/sources.list\n",
        "!apt-key adv --keyserver keyserver.ubuntu.com --recv-key 612DEFB798507F25\n",
        "!apt-get update\n",
        "!apt-get install python3-graph-tool python3-matplotlib python3-cairo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#python3-cairo from Ubuntu's reposity is linked with a different python version; we need to improvise\n",
        "#goal: recreate panther.py using graph-tool and colab\n",
        "!apt purge python3-cairo\n",
        "!apt install libcairo2-dev pkg-config python3-dev\n",
        "!pip install --force-reinstall pycairo\n",
        "!pip install zstandard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmM5oaqxoH5K",
        "outputId": "6dd0f839-b287-4326-87de-8154edc50af0"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graph_tool.all import *\n",
        "from graph_tool.topology import *"
      ],
      "metadata": {
        "id": "Nau6rLoMoxMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e4cda1-de6a-4c73-a9c0-b64f89ed0298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3/dist-packages/graph_tool/draw/cairo_draw.py:1500: RuntimeWarning: Error importing Gtk module: cannot import name '_gi' from partially initialized module 'gi' (most likely due to a circular import) (/usr/lib/python3/dist-packages/gi/__init__.py); GTK+ drawing will not work.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76AOTtxCo9CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf4VkfM82Hr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4153aa69-dbc0-4cbf-b834-2aa1f59f1647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13936676"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "U_LBqw6eXxfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(columns= ['source', 'target', 'weight'])\n",
        "\n",
        "for chunk in pd.read_csv('input.csv', chunksize=100000):\n",
        "  df = pd.concat([df, chunk])\n",
        "  df = df.groupby('source').head(100)\n",
        "  df = df.groupby('target').head(100)"
      ],
      "metadata": {
        "id": "40Pag8PP2_cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7f5a53-7195-4d7f-fe3b-eb227f028426"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "sim_dict = {}\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "#print(G.edges(node, data=\"weight\"))\n",
        "graph_vertices = {}\n",
        "\n",
        "#store indices of all graph vertices\n",
        "\n",
        "for v in g.iter_vertices():  \n",
        "  graph_vertices[v] = None\n",
        "\n",
        "\n",
        "\n",
        "while len(graph_vertices) > 0:\n",
        "\n",
        "    start_node = int(next(iter(graph_vertices)))\n",
        "\n",
        "    panther_list = {start_node}\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    \n",
        "    neighbors = [v for v in g.iter_all_neighbors(start_node)]\n",
        "\n",
        "    print(len(neighbors))\n",
        "\n",
        "    for neighbor in neighbors:\n",
        "      if neighbor not in panther_list:\n",
        "        panther_list.add(neighbor)\n",
        "    \n",
        "    \n",
        "    #get second-degree neighbors of node\n",
        "    \n",
        "    for neighbor in neighbors:\n",
        "        second_neighbors = [int(v) for v in g.iter_all_neighbors(neighbor)]\n",
        "\n",
        "        if len(panther_list) > 2500:\n",
        "            break\n",
        "        for n in second_neighbors:\n",
        "            if n not in panther_list:\n",
        "                panther_list.add(n)\n",
        "        \n",
        "        for second in second_neighbors: \n",
        "          third_neighbors = [int(v) for v in g.iter_all_neighbors(second)]\n",
        "\n",
        "          if len(panther_list) > 2500:\n",
        "            break\n",
        "          for n in third_neighbors:\n",
        "            if n not in panther_list:\n",
        "              panther_list.add(n)\n",
        "    \n",
        "    array_list = [] \n",
        "\n",
        "    proto_dict = {}\n",
        "\n",
        "    new_node = [1 if v in graph_vertices else 0 for v in panther_list]\n",
        "\n",
        "    node_count = sum(new_node)\n",
        "\n",
        "    panther_list = [x for _, x in sorted(zip(new_node, panther_list))]\n",
        "\n",
        "    panther_list.reverse()\n",
        "\n",
        "    \n",
        "\n",
        "    def filter_node(n):\n",
        "      return int(n) in panther_list\n",
        "    \n",
        "    \n",
        "    panther_subgraph = GraphView(g, vfilt=filter_node)\n",
        "\n",
        "    subgraph_vertices = [v for v in panther_subgraph.iter_vertices()]\n",
        "\n",
        "    for v in panther_list:\n",
        "        proto_dict[v] = 0\n",
        "\n",
        "    for v in panther_list:\n",
        "        node_dict = proto_dict.copy()\n",
        "        node_vec = []\n",
        "        \n",
        "        for s, t, i in panther_subgraph.iter_all_edges(v, [weight]):\n",
        "            \n",
        "            if int(s) == int(v):\n",
        "              connect = t\n",
        "            elif int(t) == int(v):\n",
        "              connect = s\n",
        "            else: \n",
        "              connect = s\n",
        "\n",
        "            node_dict[connect] = i\n",
        "\n",
        "\n",
        "        node_vec = list(node_dict.values())\n",
        "\n",
        "        array_list.append(np.array(node_vec))\n",
        "\n",
        "\n",
        "#iterate over array list, for each vector find the most similar other vectors\n",
        "#memoize responses\n",
        "    \n",
        "    \n",
        "\n",
        "    for i in range(node_count):\n",
        "\n",
        "        \n",
        "        similarities = []\n",
        "        \n",
        "        for j in range(len(array_list)):\n",
        "            sim = cos_sim(array_list[i], array_list[j])\n",
        "            similarities.append( (vmap[panther_list[j]], sim) )\n",
        "\n",
        "        similarities = sorted(similarities, key = lambda x: 100 if math.isnan(x[1]) else - x[1]) #put the similarities list in desc order\n",
        "        if len(similarities) > 51:\n",
        "            similarities = similarities[1:51] # find top 50 similarities, excluding itself\n",
        "        else:\n",
        "            similarities = similarities[1:]\n",
        "\n",
        "        vertex = vmap[panther_list[i]]  \n",
        "            \n",
        "        sim_dict[vertex] = list(similarities)\n",
        "        print(len(sim_dict))\n",
        "    \n",
        "    remove_list = panther_list[:node_count]\n",
        "\n",
        "    for node in remove_list:\n",
        "      graph_vertices.pop(node)\n",
        "\n",
        "end = time.time()\n",
        "print(\"total time: \" + str(end - start))\n",
        "\n",
        "    #panther_graph.add_nodes_from(panther_list)\n",
        "\n",
        "    #iterate over subgraph nodes\n",
        "    # create list of connections\n",
        "    #consider Jaccard coefficient and cosine similarity\n",
        "    #use graph.get_edge_data\n",
        "    \n",
        "    # changes: don't remove vertices from graph; don't calculate similarities unless\n",
        "    # you haven't yet. Calculate 100 new similarity scores at a time. Keep\n",
        "    # graph copy where you're filtering out old nodes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                            \n"
      ],
      "metadata": {
        "id": "gs2VEaThd5Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5381301-579f-47e8-af25-a0376a4457ee"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the top 1000 vertices by pagerank\n",
        "pt = pagerank(g)\n",
        "\n",
        "pair_list = [(v, pt[v]) for v in g.iter_vertices()]\n",
        "pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "top_vertices = [p[0] for p in pair_list[:1000]]\n",
        "\n",
        "pr_subgraph = GraphView(g, vfilt=lambda x: int(x) in top_vertices)"
      ],
      "metadata": {
        "id": "-Mk9sLrlXQDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate force-directed graph\n",
        "\n",
        "pos = fruchterman_reingold_layout(pr_subgraph, n_iter=100)\n",
        "graph_draw(pr_subgraph, pos=pos, output=\"graph-draw-fr.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbnRZnp_YmTa",
        "outputId": "5490452c-db8a-4fcc-9766-bba312fa5606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VertexPropertyMap object with value type 'vector<double>', for Graph 0x7fbf0474ad00, at 0x7fbf0474a5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGT-f7Xdkl0",
        "outputId": "e84cffd4-228d-40c1-d85c-8c403ba84c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "coords = []\n",
        "for v in pr_subgraph.iter_vertices():\n",
        "  dot_dict = {\"Key\": v, \"X\": pos[v][0], \"Y\": pos[v][1]}\n",
        "  coords.append(dot_dict)\n",
        "\n",
        "field_names = [\"Key\", \"X\", \"Y\"]\n",
        "\n",
        "with open('node_coords.csv', 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(coords)"
      ],
      "metadata": {
        "id": "LS8VJtV-1a29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IECXv-bey1aD",
        "outputId": "621b8bda-0782-467f-c094-f4e60911b6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3e44297258bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('similarities.csv', 'w', newline='') as csvfile:\n",
        "  header = ['track']\n",
        "  header = header + list(range(1, 51))\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=header)\n",
        "  for key in sim_dict.keys():\n",
        "    row = {}\n",
        "    row['track'] = key\n",
        "    for i in range(50):\n",
        "      if len(sim_dict[key]) > i:\n",
        "        row[i + 1] = sim_dict[key][i]\n",
        "    \n",
        "    writer.writerow(row)"
      ],
      "metadata": {
        "id": "1JCqwXDF1X87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdTAgu7QbSUu",
        "outputId": "94363bcb-1f88-45d1-c27f-5c9984a3cc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('1bWFvGIN7b5cTps09X6tZ8', 0.4590780850487671), ('2JyxMvRn57BdTCCSpGlKLG', 0.37707334353833644), ('65D95SmygxGCQGiI64eaZf', 0.365554032416927), ('5TpaWJKnuyA4MjzAbFXSTQ', 0.3177762847994256), ('3XabgBQYC7H80agKcAq83Y', 0.30834039177742634), ('09XsCShQ3oCA3a5QT5ZUG5', 0.3074558940517994), ('24PWKmemCvqfyVXODhoKHW', 0.30014336268406405), ('0EgigrGFGb4PHaVNb7fgK7', 0.2965990580714912), ('6D1CstH1YvzNN8cPd9ay9Q', 0.2815624608409983), ('6YTp4sUEi3oWNToQvOjke6', 0.2650725101465462), ('6JJ8eDRnrwORwTi6K2KFOx', 0.2631099209781971), ('5tEbnKMOMK8LLoOIsEkWRr', 0.2613801048830039), ('1LMAQunVS6Dq8wEqQnsL8Y', 0.2506147601684105), ('76dZuMVXjIyLPRLv00skGd', 0.24529926644357516), ('1NpcguIbdLR25tlymnwVVC', 0.24032578213897166), ('2boJnT3S2aSBagFEUTXrfx', 0.23374737492215086), ('0BjsCH9fQk9Y2c4uFhMFdV', 0.22568514811147514), ('6QwwsJC57SitPcWuyEpuwd', 0.22510994381306007), ('6KoK723c5pmYKiHvH69JDr', 0.22229846934137182), ('0LDsM5oTo0gKnrRMS9z03e', 0.215471208861415), ('0DW5anNzTO7h0OlKqFsVQ6', 0.21433767861360697), ('7eaEXFYxeRs0TMXFyayhdo', 0.21173980404755743), ('6Zx8kYgqiTiZzj0ZQ2aTfx', 0.2084351331602408), ('6v7k2RhTeg9R3Rc3yhtNnx', 0.20549632357522252), ('03aHYlzPaJnypjFPkEJVJy', 0.20512370980797343), ('5krOROgmf8adn3SJzeKLZy', 0.2038922522470165), ('1KLtkmQnN9pMgP6T4FdWk5', 0.20191207482553547), ('5tc5fqSM2rwgcwGcJUx8U1', 0.2002985182606912), ('1KW8BTLgbRCTH8pzUmboLE', 0.19087335479620376), ('79lmvU7Qmc8QpXilbSk37z', 0.1907163588841368), ('7i5mufbqmLZ4Ae7JnmLqp6', 0.18751353800114867), ('7eJ5kRpMNPAk7ccCDKywjH', 0.18612198233104976), ('0e42i89bY2NmPuVDtey8pg', 0.1853668759727255), ('0Wi0Pk5bSwM7WEFmDAGzL5', 0.17974578331694774), ('1wLhwzPAtze5JT8qqXlqaO', 0.1758923641108249), ('2KyiIp5r7uPc0WGeyd5Pbk', 0.17575329723601574), ('71mDjdeVK9sqXmamMHaAfX', 0.17344355039886683), ('33j4CLU9UyRjO63ry5J61Q', 0.17242390505284869), ('44BgLFzaZ09it1ugjIOJBE', 0.1673373601880206), ('6j2aNuhJJUnRj6UHcvn5PI', 0.16596896328416325), ('6giYNaycmjkbf7UmZ6RGtL', 0.16517484152505577), ('7xGk3BeEamk38gVgGinEqQ', 0.16461624615478349), ('0b0YJjeoC46wvQ9GEbtfzU', 0.16439478087189668), ('2FdQ4hkbqZ1X930oxxgZZy', 0.1569830328771999), ('0l3wp8iEtN8rgag9eTeorW', 0.14767623020869206), ('4sqGlfDc7QCPvAvUBk4OKn', 0.14085065873647884), ('6JFdyoLzHdGibgutS7LrBb', 0.140798713074105), ('5bgFKHB5Y9OqyjHaC1OhVq', 0.14070470786789493), ('1Q9b6CeMcDuO0uq5OJCrqu', 0.14049043209066348), ('563vSy3HB5NHxel1VGQCW6', 0.1359478966096835)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each node, find its neighborhood. find similarities for all the nodes that haven't been \n",
        "# counted yet."
      ],
      "metadata": {
        "id": "WEHwCobgcyhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
