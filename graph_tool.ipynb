{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR6Ow9uxoFB-",
        "outputId": "802e1a14-ad6b-4c20-f4c1-cd4beae62ee8"
      },
      "outputs": [
      ],
      "source": [
        "#Commands for installing graph-tool package on Google Colab\n",
        "!echo \"deb http://downloads.skewed.de/apt bionic main\" >> /etc/apt/sources.list\n",
        "!apt-key adv --keyserver keyserver.ubuntu.com --recv-key 612DEFB798507F25\n",
        "!apt-get update\n",
        "!apt-get install python3-graph-tool python3-matplotlib python3-cairo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#python3-cairo from Ubuntu's reposity is linked with a different python version; we need to improvise\n",
        "#goal: recreate panther.py using graph-tool and colab\n",
        "!apt purge python3-cairo\n",
        "!apt install libcairo2-dev pkg-config python3-dev\n",
        "!pip install --force-reinstall pycairo\n",
        "!pip install zstandard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmM5oaqxoH5K",
        "outputId": "6dd0f839-b287-4326-87de-8154edc50af0"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graph_tool.all import *\n",
        "from graph_tool.topology import *"
      ],
      "metadata": {
        "id": "Nau6rLoMoxMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e4cda1-de6a-4c73-a9c0-b64f89ed0298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3/dist-packages/graph_tool/draw/cairo_draw.py:1500: RuntimeWarning: Error importing Gtk module: cannot import name '_gi' from partially initialized module 'gi' (most likely due to a circular import) (/usr/lib/python3/dist-packages/gi/__init__.py); GTK+ drawing will not work.\n",
            "  warnings.warn(msg, RuntimeWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76AOTtxCo9CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf4VkfM82Hr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4153aa69-dbc0-4cbf-b834-2aa1f59f1647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13936676"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "U_LBqw6eXxfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame(columns= ['source', 'target', 'weight'])\n",
        "\n",
        "for chunk in pd.read_csv('input.csv', chunksize=100000):\n",
        "  df = pd.concat([df, chunk])\n",
        "  df = df.groupby('source').head(100)\n",
        "  df = df.groupby('target').head(100)"
      ],
      "metadata": {
        "id": "40Pag8PP2_cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7f5a53-7195-4d7f-fe3b-eb227f028426"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "# initializing graph from pandas frame\n",
        "g = Graph()\n", 
        "weight = g.new_edge_property('int')\n",
        "vmap = g.add_edge_list(df.values, hashed=True, eprops=[weight])\n",
        "sim_dict = {}\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "graph_vertices = {}\n",
        "\n",
        "#store indices of all graph vertices\n",
        "\n",
        "for v in g.iter_vertices():  \n",
        "  graph_vertices[v] = None\n",
        "\n",
        "\n",
        "\n",
        "while len(graph_vertices) > 0:\n",
        "\n",
        "    start_node = int(next(iter(graph_vertices)))\n",
        "\n",
        "    panther_list = {start_node}\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    \n",
        "    neighbors = [v for v in g.iter_all_neighbors(start_node)]\n",
        "\n",
        "    print(len(neighbors))\n",
        "\n",
        "    for neighbor in neighbors:\n",
        "      if neighbor not in panther_list:\n",
        "        panther_list.add(neighbor)\n",
        "    \n",
        "    \n",
        "    #get second-degree neighbors of node\n",
        "    \n",
        "    for neighbor in neighbors:\n",
        "        second_neighbors = [int(v) for v in g.iter_all_neighbors(neighbor)]\n",
        "\n",
        "        if len(panther_list) > 2500:\n",
        "            break\n",
        "        for n in second_neighbors:\n",
        "            if n not in panther_list:\n",
        "                panther_list.add(n)\n",
        "        \n",
        "        for second in second_neighbors: \n",
        "          third_neighbors = [int(v) for v in g.iter_all_neighbors(second)]\n",
        "\n",
        "          if len(panther_list) > 2500:\n",
        "            break\n",
        "          for n in third_neighbors:\n",
        "            if n not in panther_list:\n",
        "              panther_list.add(n)\n",
        "    \n",
        "    array_list = [] \n",
        "\n",
        "    proto_dict = {}\n",
        "\n",
        "    new_node = [1 if v in graph_vertices else 0 for v in panther_list]\n",
        "\n",
        "    node_count = sum(new_node)\n",
        "\n",
        "    panther_list = [x for _, x in sorted(zip(new_node, panther_list))]\n",
        "\n",
        "    panther_list.reverse()\n",
        "\n",
        "    \n",
        "\n",
        "    def filter_node(n):\n",
        "      return int(n) in panther_list\n",
        "    \n",
        "    \n",
        "    panther_subgraph = GraphView(g, vfilt=filter_node)\n",
        "\n",
        "    subgraph_vertices = [v for v in panther_subgraph.iter_vertices()]\n",
        "\n",
        "    for v in panther_list:\n",
        "        proto_dict[v] = 0\n",
        "\n",
        "    for v in panther_list:\n",
        "        node_dict = proto_dict.copy()\n",
        "        node_vec = []\n",
        "        \n",
        "        for s, t, i in panther_subgraph.iter_all_edges(v, [weight]):\n",
        "            \n",
        "            if int(s) == int(v):\n",
        "              connect = t\n",
        "            elif int(t) == int(v):\n",
        "              connect = s\n",
        "            else: \n",
        "              connect = s\n",
        "\n",
        "            node_dict[connect] = i\n",
        "\n",
        "\n",
        "        node_vec = list(node_dict.values())\n",
        "\n",
        "        array_list.append(np.array(node_vec))\n",
        "\n",
        "\n",
        "#iterate over array list, for each vector find the most similar other vectors\n",
        "#memoize responses\n",
        "    \n",
        "    \n",
        "\n",
        "    for i in range(node_count):\n",
        "\n",
        "        \n",
        "        similarities = []\n",
        "        \n",
        "        for j in range(len(array_list)):\n",
        "            sim = cos_sim(array_list[i], array_list[j])\n",
        "            similarities.append( (vmap[panther_list[j]], sim) )\n",
        "\n",
        "        similarities = sorted(similarities, key = lambda x: 100 if math.isnan(x[1]) else - x[1]) #put the similarities list in desc order\n",
        "        if len(similarities) > 51:\n",
        "            similarities = similarities[1:51] # find top 50 similarities, excluding itself\n",
        "        else:\n",
        "            similarities = similarities[1:]\n",
        "\n",
        "        vertex = vmap[panther_list[i]]  \n",
        "            \n",
        "        sim_dict[vertex] = list(similarities)\n",
        "        print(len(sim_dict))\n",
        "    \n",
        "    remove_list = panther_list[:node_count]\n",
        "\n",
        "    for node in remove_list:\n",
        "      graph_vertices.pop(node)\n",
        "\n",
        "end = time.time()\n",
        "print(\"total time: \" + str(end - start))\n",
        "\n",
        "    #panther_graph.add_nodes_from(panther_list)\n",
        "\n",
        "    #iterate over subgraph nodes\n",
        "    # create list of connections\n",
        "    #consider Jaccard coefficient and cosine similarity\n",
        "    #use graph.get_edge_data\n",
        "    \n",
        "    # changes: don't remove vertices from graph; don't calculate similarities unless\n",
        "    # you haven't yet. Calculate 100 new similarity scores at a time. Keep\n",
        "    # graph copy where you're filtering out old nodes.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                            \n"
      ],
      "metadata": {
        "id": "gs2VEaThd5Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5381301-579f-47e8-af25-a0376a4457ee"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get the top 1000 vertices by pagerank\n",
        "pt = pagerank(g)\n",
        "\n",
        "pair_list = [(v, pt[v]) for v in g.iter_vertices()]\n",
        "pair_list = sorted(pair_list, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "top_vertices = [p[0] for p in pair_list[:1000]]\n",
        "\n",
        "pr_subgraph = GraphView(g, vfilt=lambda x: int(x) in top_vertices)"
      ],
      "metadata": {
        "id": "-Mk9sLrlXQDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate force-directed graph\n",
        "\n",
        "pos = fruchterman_reingold_layout(pr_subgraph, n_iter=100)\n",
        "graph_draw(pr_subgraph, pos=pos, output=\"graph-draw-fr.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbnRZnp_YmTa",
        "outputId": "5490452c-db8a-4fcc-9766-bba312fa5606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VertexPropertyMap object with value type 'vector<double>', for Graph 0x7fbf0474ad00, at 0x7fbf0474a5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGT-f7Xdkl0",
        "outputId": "e84cffd4-228d-40c1-d85c-8c403ba84c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "coords = []\n",
        "for v in pr_subgraph.iter_vertices():\n",
        "  dot_dict = {\"Key\": v, \"X\": pos[v][0], \"Y\": pos[v][1]}\n",
        "  coords.append(dot_dict)\n",
        "\n",
        "field_names = [\"Key\", \"X\", \"Y\"]\n",
        "\n",
        "with open('node_coords.csv', 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(coords)"
      ],
      "metadata": {
        "id": "LS8VJtV-1a29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "IECXv-bey1aD",
        "outputId": "621b8bda-0782-467f-c094-f4e60911b6d1"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "with open('similarities.csv', 'w', newline='') as csvfile:\n",
        "  header = ['track']\n",
        "  header = header + list(range(1, 51))\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=header)\n",
        "  for key in sim_dict.keys():\n",
        "    row = {}\n",
        "    row['track'] = key\n",
        "    for i in range(50):\n",
        "      if len(sim_dict[key]) > i:\n",
        "        row[i + 1] = sim_dict[key][i]\n",
        "    \n",
        "    writer.writerow(row)"
      ],
      "metadata": {
        "id": "1JCqwXDF1X87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdTAgu7QbSUu",
        "outputId": "94363bcb-1f88-45d1-c27f-5c9984a3cc54"
      },
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for each node, find its neighborhood. find similarities for all the nodes that haven't been \n",
        "# counted yet."
      ],
      "metadata": {
        "id": "WEHwCobgcyhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
